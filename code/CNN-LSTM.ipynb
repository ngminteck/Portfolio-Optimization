{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bc6f70-92a8-48ce-a43c-c50ef323401e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of logical CPU cores: 16\n",
      "Number of workers set to: 8\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, root_mean_squared_error , mean_squared_error\n",
    "\n",
    "logical_cores = os.cpu_count()\n",
    "print(f\"Number of logical CPU cores: {logical_cores}\")\n",
    "\n",
    "num_workers = max(1, logical_cores // 2)\n",
    "print(f\"Number of workers set to: {num_workers}\")\n",
    "\n",
    "def is_gpu_available():\n",
    "    try:\n",
    "        return torch.cuda.is_available()\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "gpu_available = is_gpu_available()\n",
    "print(f\"GPU available: {gpu_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2fddba8-475e-4ee4-94f2-e23eb2c04840",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../models/pytorch/conv1d-classification/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/conv1d-regression/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/lstm-classification/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/lstm-regression/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/conv1d-classification-lstm-classification/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/conv1d-classification-lstm-regression/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/conv1d-regression-lstm-classification/', exist_ok=True)\n",
    "os.makedirs('../models/pytorch/conv1d-regression-lstm-regression/', exist_ok=True)\n",
    "\n",
    "path = '../data'\n",
    "ticker_list = []\n",
    "\n",
    "if os.path.exists(path):\n",
    "    ticker_list = [os.path.splitext(f)[0] for f in os.listdir(path) if f.endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ea84ad-a104-4fc3-8226-cc50191547b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    if df.isna().sum().sum() > 0 or df.isin([float('inf'), float('-inf')]).sum().sum() > 0:\n",
    "        df = df.replace([float('inf'), float('-inf')], float('nan')).dropna()\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    columns_to_drop = [\n",
    "        'NEXT_DAY_CLOSEPRICE', 'DAILY_CLOSEPRICE_CHANGE', 'CLOSEPRICE_DIRECTION',\n",
    "        'DAILY_MIDPRICE', 'NEXT_DAY_MIDPRICE', 'DAILY_MIDPRICE_CHANGE', 'MIDPRICE_DIRECTION', 'Date'\n",
    "    ]\n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y_classifier = (df['DAILY_CLOSEPRICE_CHANGE'] > 0).astype(int)\n",
    "    y_regressor = df['DAILY_CLOSEPRICE_CHANGE']\n",
    "\n",
    "    return X, y_classifier, y_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def88067-ef68-4213-bcde-cc93c12a32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, l2_lambda=0.01):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding='same')\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=1, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "        \n",
    "        self.l2_lambda = l2_lambda\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.residual_conv = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        else:\n",
    "            self.residual_conv = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual_conv(x)\n",
    "        print(f'ResidualBlock - Input shape: {x.shape}')\n",
    "        out = self.conv1(x)\n",
    "        print(f'ResidualBlock - After conv1: {out.shape}')\n",
    "        out = self.bn1(out)\n",
    "        print(f'ResidualBlock - After bn1: {out.shape}')\n",
    "        out = self.relu(out)\n",
    "        print(f'ResidualBlock - After relu1: {out.shape}')\n",
    "        out = self.conv2(out)\n",
    "        print(f'ResidualBlock - After conv2: {out.shape}')\n",
    "        out = self.bn2(out)\n",
    "        print(f'ResidualBlock - After bn2: {out.shape}')\n",
    "        out += residual\n",
    "        print(f'ResidualBlock - After adding residual: {out.shape}')\n",
    "        out = self.relu(out)\n",
    "        print(f'ResidualBlock - After relu2: {out.shape}')\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Conv1DModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_blocks=1, l2_lambda=0.01, classification=True):\n",
    "        super(Conv1DModel, self).__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualBlock(in_channels, out_channels, kernel_size, l2_lambda=l2_lambda) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # Global average pooling for 1D\n",
    "        self.fc = nn.Linear(out_channels, 2 if classification else 1)\n",
    "        self.classification = classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'Conv1DModel - Input shape: {x.shape}')\n",
    "        out = self.blocks(x)\n",
    "        print(f'Conv1DModel - After residual blocks: {out.shape}')\n",
    "        out = self.global_avg_pool(out)\n",
    "        print(f'Conv1DModel - After global average pooling: {out.shape}')\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        print(f'Conv1DModel - After flattening: {out.shape}')\n",
    "        out = self.fc(out)\n",
    "        print(f'Conv1DModel - After fully connected layer: {out.shape}')\n",
    "        if self.classification:\n",
    "            out = F.log_softmax(out, dim=1)\n",
    "            print(f'Conv1DModel - After log_softmax: {out.shape}')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39830c3-534d-46dc-ad91-6ee2082177da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conv1d(X, y, classification, gpu_available, ticker):\n",
    "    device = torch.device('cuda' if gpu_available and torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # Convert DataFrame to numpy array\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    \n",
    "    # Reshape X for Conv1D\n",
    "    NUM_CHANNELS = 1\n",
    "    X = X.reshape((X.shape[0], NUM_CHANNELS, -1))  # Reshape for Conv1D: (batch_size, num_channels, sequence_length)\n",
    "    print(f'process_conv1d - Input shape after reshaping: {X.shape}')\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    TEST_SIZE = 0.2\n",
    "    RANDOM_STATE = 42\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    print(f'process_conv1d - Training data shape: {X_train.shape}, Validation data shape: {X_val.shape}')\n",
    "    \n",
    "    def conv1d_objective(trial):\n",
    "        in_channels = X_train.shape[1]  # Ensure this matches the reshaped input\n",
    "        out_channels = trial.suggest_int('out_channels', 16, 128)\n",
    "        kernel_size = trial.suggest_int('kernel_size', 3, 7)\n",
    "        num_blocks = trial.suggest_int('num_blocks', 1, 10)\n",
    "        l2_lambda = trial.suggest_float('l2_lambda', 1e-5, 1e-2)\n",
    "        \n",
    "        model = Conv1DModel(in_channels, out_channels, kernel_size, num_blocks, l2_lambda, classification).to(device)\n",
    "        print(f'conv1d_objective - Model initialized with in_channels={in_channels}, out_channels={out_channels}, kernel_size={kernel_size}, num_blocks={num_blocks}')\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=trial.suggest_float('lr', 1e-5, 1e-2), weight_decay=l2_lambda)\n",
    "        criterion = nn.CrossEntropyLoss() if classification else nn.MSELoss()\n",
    "        \n",
    "        input_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        target_train = torch.tensor(y_train, dtype=torch.long if classification else torch.float32).to(device)\n",
    "        \n",
    "        model.train()\n",
    "        EPOCHS = 10\n",
    "        for epoch in range(EPOCHS):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_train)\n",
    "            print(f'conv1d_objective - Epoch {epoch}: Output shape: {output.shape}')\n",
    "            loss = criterion(output, target_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        input_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "        target_val = torch.tensor(y_val, dtype=torch.long if classification else torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            val_output = model(input_val)\n",
    "            val_loss = criterion(val_output, target_val)\n",
    "            if classification:\n",
    "                val_accuracy = (val_output.argmax(dim=1) == target_val).float().mean().item()\n",
    "                print(f'conv1d_objective - Trial {trial.number}: Validation Accuracy = {val_accuracy:.4f}, Validation Loss = {val_loss.item():.4f}')\n",
    "                return 1 - val_accuracy\n",
    "            else:\n",
    "                val_mse = val_loss.item()\n",
    "                print(f'conv1d_objective - Trial {trial.number}: Validation MSE = {val_mse:.4f}, Validation Loss = {val_loss.item():.4f}')\n",
    "                return val_mse\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(conv1d_objective, n_trials=100)\n",
    "    \n",
    "    best_model = Conv1DModel(X.shape[1], study.best_params['out_channels'], study.best_params['kernel_size'], study.best_params['num_blocks'], study.best_params['l2_lambda'], classification).to(device)\n",
    "    \n",
    "    # Save the best model\n",
    "    model_type = 'classification' if classification else 'regression'\n",
    "    torch.save(best_model.state_dict(), f'../models/pytorch/conv1d-{model_type}/{ticker}.pth')\n",
    "    \n",
    "    # Print out metrics for the best model\n",
    "    best_model.eval()\n",
    "    input_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    target_val = torch.tensor(y_val, dtype=torch.long if classification else torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        val_output = best_model(input_val)\n",
    "        val_loss = criterion(val_output, target_val)\n",
    "        val_accuracy = (val_output.argmax(dim=1) == target_val).float().mean().item()\n",
    "        val_mse =val_mse = val_loss.item()\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        print(f'Validation MSE: {val_mse:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9de1e0-a044-47e9-85cf-6b3a1a97808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-04 12:14:31,034] A new study created in memory with name: no-name-44a4cc74-5690-46e3-8eb3-26e98fff73b2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "process_conv1d - Input shape after reshaping: (163, 1, 100)\n",
      "process_conv1d - Training data shape: (130, 1, 100), Validation data shape: (33, 1, 100)\n",
      "conv1d_objective - Model initialized with in_channels=1, out_channels=105, kernel_size=4, num_blocks=6\n",
      "Conv1DModel - Input shape: torch.Size([130, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:304: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:1032.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "[W 2024-09-04 12:14:32,601] Trial 0 failed with parameters: {'out_channels': 105, 'kernel_size': 4, 'num_blocks': 6, 'l2_lambda': 0.0055368679208314285, 'lr': 0.0030196163140850814} because of the following error: RuntimeError('Given groups=1, weight of size [105, 1, 1], expected input[130, 105, 100] to have 1 channels, but got 105 channels instead').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_6204\\1126740852.py\", line 40, in conv1d_objective\n",
      "    output = model(input_train)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_6204\\2242429598.py\", line 62, in forward\n",
      "    out = self.blocks(x)\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_6204\\2242429598.py\", line 24, in forward\n",
      "    residual = self.residual_conv(x)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 308, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ng_mi\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 304, in _conv_forward\n",
      "    return F.conv1d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Given groups=1, weight of size [105, 1, 1], expected input[130, 105, 100] to have 1 channels, but got 105 channels instead\n",
      "[W 2024-09-04 12:14:32,605] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualBlock - Input shape: torch.Size([130, 1, 100])\n",
      "ResidualBlock - After conv1: torch.Size([130, 105, 100])\n",
      "ResidualBlock - After bn1: torch.Size([130, 105, 100])\n",
      "ResidualBlock - After relu1: torch.Size([130, 105, 100])\n",
      "ResidualBlock - After conv2: torch.Size([130, 105, 100])\n",
      "ResidualBlock - After bn2: torch.Size([130, 105, 100])\n",
      "ResidualBlock - After adding residual: torch.Size([130, 105, 100])\n",
      "ResidualBlock - After relu2: torch.Size([130, 105, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [105, 1, 1], expected input[130, 105, 100] to have 1 channels, but got 105 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m X, y_classifier, y_regressor \u001b[38;5;241m=\u001b[39m preprocess_data(dataframe)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mprocess_conv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_available\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#process_conv1dlstm(X, y_classifier, y_regressor, True, False, gpu_available, ticker)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 63\u001b[0m, in \u001b[0;36mprocess_conv1d\u001b[1;34m(X, y, classification, gpu_available, ticker)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m val_mse\n\u001b[0;32m     62\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv1d_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m best_model \u001b[38;5;241m=\u001b[39m Conv1DModel(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_channels\u001b[39m\u001b[38;5;124m'\u001b[39m], study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m], study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_blocks\u001b[39m\u001b[38;5;124m'\u001b[39m], study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m], classification)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m, in \u001b[0;36mprocess_conv1d.<locals>.conv1d_objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 40\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1d_objective - Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target_train)\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 62\u001b[0m, in \u001b[0;36mConv1DModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv1DModel - Input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv1DModel - After residual blocks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_avg_pool(out)\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResidualBlock - Input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\pytorch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [105, 1, 1], expected input[130, 105, 100] to have 1 channels, but got 105 channels instead"
     ]
    }
   ],
   "source": [
    "for ticker in ticker_list:\n",
    "    dataframe = pd.read_csv(f\"../data/{ticker}.csv\")\n",
    "    X, y_classifier, y_regressor = preprocess_data(dataframe)\n",
    "    process_conv1d(X, y_classifier, True, gpu_available, ticker)\n",
    "    #process_conv1dlstm(X, y_classifier, y_regressor, True, False, gpu_available, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219e589a-9fa0-4de2-a3bb-1c54ecf2f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, sequence_length, classification=True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.classification = classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        if self.classification:\n",
    "            out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "def process_lstm(X, y, classification, gpu_available, ticker):\n",
    "    device = torch.device('cuda' if gpu_available and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Convert DataFrame to numpy array\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "  \n",
    "    # Reshape X for LSTM\n",
    "    X = X.reshape((X.shape[0], -1, 1))  # Reshape for LSTM: (batch_size, sequence_length, num_features)\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    input_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    target_val = torch.tensor(y_val, dtype=torch.long if classification else torch.float32).to(device)\n",
    "    \n",
    "    def lstm_objective(trial):\n",
    "        input_size = X.shape[2]\n",
    "        hidden_size = trial.suggest_int('hidden_size', 16, 128)\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "        sequence_length = X.shape[1]\n",
    "        \n",
    "        model = LSTMModel(input_size, hidden_size, num_layers, 2 if classification else 1, sequence_length, classification).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=trial.suggest_float('lr', 1e-5, 1e-2))\n",
    "        criterion = nn.CrossEntropyLoss() if classification else nn.MSELoss()\n",
    "        \n",
    "        input_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        target_train = torch.tensor(y_train, dtype=torch.long if classification else torch.float32).to(device)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(10):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_train)\n",
    "            loss = criterion(output, target_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output = model(input_val)\n",
    "            val_loss = criterion(val_output, target_val)\n",
    "            val_accuracy = (val_output.argmax(dim=1) == target_val).float().mean().item()\n",
    "            val_mse =val_mse = val_loss.item()\n",
    "            print(f'Trial {trial.number}: Validation Accuracy = {val_accuracy:.4f}, Validation MSE = {val_mse:.4f}, Validation Loss = {val_loss.item():.4f}')\n",
    "            return 1 - accuracy if classification else mse\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lstm_objective, n_trials=100)\n",
    "    \n",
    "    best_model = LSTMModel(X.shape[2], study.best_params['hidden_size'], study.best_params['num_layers'], 2 if classification else 1, X.shape[1], classification).to(device)\n",
    "    \n",
    "    # Save the best model\n",
    "    model_type = 'classification' if classification else 'regression'\n",
    "    torch.save(best_model.state_dict(), f'../models/pytorch/lstm-{model_type}/{ticker}.pth')\n",
    "    \n",
    "    # Print out metrics for the best model\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = best_model(input_val)\n",
    "        val_loss = criterion(val_output, target_val)\n",
    "        val_accuracy = (val_output.argmax(dim=1) == target_val).float().mean().item()\n",
    "        val_mse =val_mse = val_loss.item()\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        print(f'Validation MSE: {val_mse:.4f}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b631aa9-2997-4e39-9881-8df3f0891a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, lstm_input_size, lstm_hidden_size, lstm_num_layers, output_size, classification=True):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.lstm = nn.LSTM(lstm_input_size, lstm_hidden_size, lstm_num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, output_size)\n",
    "        self.classification = classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, sequence_length, num_channels)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "def process_conv1dlstm(X, y_classifier, y_regressor, conv1d_classification, lstm_classification, gpu_available, ticker):\n",
    "    device = torch.device('cuda' if gpu_available and torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Convert DataFrame to numpy array\n",
    "    X = X.to_numpy()\n",
    "    y_classifier = y_classifier.to_numpy()\n",
    "    y_regressor = y_regressor.to_numpy()\n",
    "    \n",
    "    # Reshape X for ConvLSTM\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))  # Reshape for Conv1D: (batch_size, num_channels, sequence_length)\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    y = y_classifier if conv1d_classification else y_regressor\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    input_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    target_val = torch.tensor(y_val, dtype=torch.long if conv1d_classification else torch.float32).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() if conv1d_classification else nn.MSELoss()\n",
    "    \n",
    "    def conv_lstm_objective(trial):\n",
    "        in_channels = X.shape[1]\n",
    "        out_channels = trial.suggest_int('out_channels', 16, 128)\n",
    "        kernel_size = trial.suggest_int('kernel_size', 3, 7)\n",
    "        lstm_hidden_size = trial.suggest_int('lstm_hidden_size', 16, 128)\n",
    "        lstm_num_layers = trial.suggest_int('lstm_num_layers', 1, 3)\n",
    "        output_size = len(set(y_classifier)) if conv1d_classification else 1  # Number of classes for classification\n",
    "        \n",
    "        model = ConvLSTMModel(in_channels, out_channels, kernel_size, out_channels, lstm_hidden_size, lstm_num_layers, output_size, classification=conv1d_classification).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=trial.suggest_float('lr', 1e-5, 1e-2))\n",
    "        criterion = nn.CrossEntropyLoss() if conv1d_classification else nn.MSELoss()\n",
    "        \n",
    "        input_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        target_train = torch.tensor(y_train, dtype=torch.long if conv1d_classification else torch.float32).to(device)\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(10):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_train)\n",
    "            loss = criterion(output, target_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output = model(input_val)\n",
    "            val_loss = criterion(val_output, target_val)\n",
    "            val_accuracy = (val_output.argmax(dim=1) == target_val).float().mean().item()\n",
    "            val_mse =val_mse = val_loss.item()\n",
    "            print(f'Trial {trial.number}: Validation Accuracy = {val_accuracy:.4f}, Validation MSE = {val_mse:.4f}, Validation Loss = {val_loss.item():.4f}')\n",
    "            return val_loss.item()\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(conv_lstm_objective, n_trials=100)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_model = ConvLSTMModel(X.shape[1], best_params['out_channels'], best_params['kernel_size'], best_params['out_channels'], best_params['lstm_hidden_size'], best_params['lstm_num_layers'], len(set(y_classifier)) if conv1d_classification else 1, classification=conv1d_classification).to(device)\n",
    "    \n",
    "    # Save the best model\n",
    "    conv_model_type = 'classification' if conv1d_classification else 'regression'\n",
    "    lstm_model_type = 'classification' if lstm_classification else 'regression'\n",
    "    torch.save(best_model.state_dict(), f'../models/pytorch/conv1d-{conv_model_type}-lstm-{lstm_model_type}/{ticker}.pth')\n",
    "    \n",
    "    # Evaluate the best model on the validation set\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = best_model(input_val)\n",
    "        val_loss = criterion(val_output, target_val)\n",
    "        val_accuracy = (val_output.argmax(dim=1) == target_val).float().mean().item()\n",
    "        val_mse =val_mse = val_loss.item()\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        print(f'Validation MSE: {val_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf355ec-470c-41b8-a691-ec8ab9b6f12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
