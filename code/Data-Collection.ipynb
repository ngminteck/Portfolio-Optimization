{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7266c9fa-9e81-4960-bf14-172ba4e4b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge libta-lib\n",
    "#conda install -c conda-forge ta-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ea29cf-0d47-4c94-85e0-c0b598ac6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import talib\n",
    "from datetime import datetime, timedelta\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from urllib.parse import quote\n",
    "import feedparser\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fe8ae1-b658-4859-a4bc-6740aafd8712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\wilso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "class NewsSentiment:\n",
    "    def __init__(self):\n",
    "        # Define the download directory\n",
    "        download_dir = os.path.join(os.path.dirname(__file__), '../nltk')\n",
    "\n",
    "        # Download the 'punkt' package to the specified directory\n",
    "        nltk.download('punkt', download_dir=download_dir)\n",
    "\n",
    "        # Add the download directory to the NLTK data path\n",
    "        nltk.data.path.append(download_dir)\n",
    "        # Load the Loughran-McDonald word lists\n",
    "        lm_dict = pd.read_csv('../nltk/Loughran-McDonald_MasterDictionary_1993-2023.csv')\n",
    "\n",
    "        # Extract sentiment word lists\n",
    "        self.negative_words = lm_dict[lm_dict['Negative'] > 0]['Word'].tolist()\n",
    "        self.positive_words = lm_dict[lm_dict['Positive'] > 0]['Word'].tolist()\n",
    "        self.uncertainty_words = lm_dict[lm_dict['Uncertainty'] > 0]['Word'].tolist()\n",
    "        self.litigious_words = lm_dict[lm_dict['Litigious'] > 0]['Word'].tolist()\n",
    "        self.strong_modal_words = lm_dict[lm_dict['Strong_Modal'] > 0]['Word'].tolist()\n",
    "        self.weak_modal_words = lm_dict[lm_dict['Weak_Modal'] > 0]['Word'].tolist()\n",
    "        self.constraining_words = lm_dict[lm_dict['Constraining'] > 0]['Word'].tolist()\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_news_titles_by_feedparser(search_queries):\n",
    "        feed_list = []\n",
    "        for query in search_queries:\n",
    "            encoded_query = quote(query)\n",
    "            rss_url = f\"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en\"\n",
    "            feed = feedparser.parse(rss_url)\n",
    "            for entry in feed.entries:\n",
    "                published_date = datetime(*entry.published_parsed[:6])\n",
    "                feed_list.append({\"title\": entry.title, \"published_date\": published_date})\n",
    "        return feed_list\n",
    "\n",
    "    def get_news_sentiment_score_by_feedparser(self, df, search_queries):\n",
    "\n",
    "        sentiment_df = df.copy(deep=True)\n",
    "        sentiment_df = sentiment_df.drop(columns=sentiment_df.columns)\n",
    "        sentiment_df[\"SENTIMENT_NEGATIVE\"] = 0.0\n",
    "        sentiment_df[\"SENTIMENT_POSITIVE\"] = 0.0\n",
    "        sentiment_df[\"SENTIMENT_UNCERTAINTY\"] = 0.0\n",
    "        sentiment_df[\"SENTIMENT_LITIGIOUS\"] = 0.0\n",
    "        sentiment_df[\"SENTIMENT_STRONG_MODAL\"] = 0.0\n",
    "        sentiment_df[\"SENTIMENT_WEAK_MODAL\"] = 0.0\n",
    "        sentiment_df[\"SENTIMENT_CONSTRAINING\"] = 0.0\n",
    "        sentiment_df[\"START_DATE\"] = sentiment_df.index.to_series().shift(1) + pd.Timedelta(days=1)\n",
    "\n",
    "        all_titles = self.fetch_news_titles_by_feedparser(search_queries)\n",
    "\n",
    "        for i in range(1, len(sentiment_df)):\n",
    "            start_date = sentiment_df.iloc[i][\"START_DATE\"]\n",
    "            end_date = sentiment_df.index[i]\n",
    "            text_list = [entry[\"title\"] for entry in all_titles if start_date <= entry[\"published_date\"] <= end_date]\n",
    "\n",
    "            for text in text_list:\n",
    "                words = word_tokenize(text.upper())\n",
    "\n",
    "                for word in words:\n",
    "                    if word in self.negative_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_NEGATIVE'] += 1.0\n",
    "                    if word in self.positive_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_POSITIVE'] += 1.0\n",
    "                    if word in self.uncertainty_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_UNCERTAINTY'] += 1.0\n",
    "                    if word in self.litigious_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_LITIGIOUS'] += 1.0\n",
    "                    if word in self.strong_modal_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_STRONG_MODAL'] += 1.0\n",
    "                    if word in self.weak_modal_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_WEAK_MODAL'] += 1.0\n",
    "                    if word in self.constraining_words:\n",
    "                        sentiment_df.loc[sentiment_df.index[i], 'SENTIMENT_CONSTRAINING'] += 1.0\n",
    "\n",
    "        sentiment_df = sentiment_df.drop(['START_DATE'], axis=1, errors='ignore')\n",
    "\n",
    "        df = pd.concat([df, sentiment_df], axis=1)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012a6c00-9096-4b4e-9f07-482aa4d5b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_technical_indicator(df):\n",
    "  \n",
    "    # Bollinger Bands: Indicates overbought/oversold conditions\n",
    "    df['BB_UPPER'], df['BB_MIDDLE'], df['BB_LOWER'] = talib.BBANDS(df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    # BB_UPPER: Upper Bollinger Band\n",
    "    # BB_MIDDLE: Middle Bollinger Band (20-period moving average)\n",
    "    # BB_LOWER: Lower Bollinger Band\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Double Exponential Moving Average: Smooths price data\n",
    "    df['DEMA'] = talib.DEMA(df['Close'], timeperiod=30)\n",
    "    # DEMA: Double Exponential Moving Average with a period of 30\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Exponential Moving Average: Smooths price data\n",
    "    df['EMA'] = talib.EMA(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity\n",
    "\n",
    "    # Hilbert Transform - Instantaneous Trendline: Identifies trend direction\n",
    "    df['HT_TRENDLINE'] = talib.HT_TRENDLINE(df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "\n",
    "    # Kaufman Adaptive Moving Average: Adjusts to market volatility\n",
    "    df['KAMA'] = talib.KAMA(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Moving Average: Smooths price data\n",
    "    df['MA'] = talib.MA(df['Close'], timeperiod=30, matype=0)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # MESA Adaptive Moving Average: Adapts to market cycles\n",
    "    df['MAMA'], df['FAMA'] = talib.MAMA(df['Close'], fastlimit=0.5, slowlimit=0.05)\n",
    "    # Value range: [negative infinity, positive infinity\n",
    "    \n",
    "    # Moving Average with Variable Period: Smooths price data with variable periods\n",
    "    df['MAVP'] = talib.MAVP(df['Close'], df['Volume'], minperiod=2, maxperiod=30, matype=0)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # MidPoint over Period: Average of the highest and lowest prices\n",
    "    df['MIDPOINT'] = talib.MIDPOINT(df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Midpoint Price over Period: Average of the highest and lowest prices\n",
    "    df['MIDPRICE'] = talib.MIDPRICE(df['High'], df['Low'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Parabolic SAR: Identifies potential reversal points\n",
    "    df['SAR'] = talib.SAR(df['High'], df['Low'], acceleration=0.02, maximum=0.2)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Parabolic SAR - Extended: Identifies potential reversal points with extended parameters\n",
    "    df['SAREXT'] = talib.SAREXT(df['High'], df['Low'], startvalue=0, offsetonreverse=0, accelerationinitlong=0.02, accelerationlong=0.02, accelerationmaxlong=0.2, accelerationinitshort=0.02, accelerationshort=0.02, accelerationmaxshort=0.2)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Simple Moving Average: Smooths price data\n",
    "    df['SMA'] = talib.SMA(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Triple Exponential Moving Average (T3): Smooths price data with less lag\n",
    "    df['T3'] = talib.T3(df['Close'], timeperiod=5, vfactor=0.7)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Triple Exponential Moving Average: Smooths price data\n",
    "    df['TEMA'] = talib.TEMA(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Triangular Moving Average: Smooths price data\n",
    "    df['TRIMA'] = talib.TRIMA(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    \n",
    "    # Weighted Moving Average: Smooths price data\n",
    "    df['WMA'] = talib.WMA(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "\n",
    "    # Momentum Indicators\n",
    "\n",
    "    # Average Directional Movement Index: Measures trend strength\n",
    "    df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Higher ADX values indicate a stronger trend. Values above 25 suggest a strong trend.\n",
    "    \n",
    "    # Average Directional Movement Index Rating: Measures trend strength\n",
    "    df['ADXR'] = talib.ADXR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Higher ADXR values indicate a stronger trend. Values above 25 suggest a strong trend.\n",
    "    \n",
    "    # Absolute Price Oscillator: Measures momentum\n",
    "    df['APO'] = talib.APO(df['Close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive APO values indicate upward momentum. Negative APO values indicate downward momentum.\n",
    "    \n",
    "    # Aroon: Identifies trend changes\n",
    "    df['AROON_down'], df['AROON_up'] = talib.AROON(df['High'], df['Low'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Higher AROON_up values indicate a stronger uptrend. Higher AROON_down values indicate a stronger downtrend.\n",
    "    \n",
    "    # Aroon Oscillator: Measures trend strength\n",
    "    df['AROONOSC'] = talib.AROONOSC(df['High'], df['Low'], timeperiod=14)\n",
    "    # Value range: [-100, 100]\n",
    "    # Example: Positive AROONOSC values indicate upward momentum. Negative AROONOSC values indicate downward momentum.\n",
    "    \n",
    "    # Balance Of Power: Measures buying and selling pressure\n",
    "    df['BOP'] = talib.BOP(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "    # Value range: [-1, 1]\n",
    "    # Example: Positive BOP values indicate buying pressure. Negative BOP values indicate selling pressure.\n",
    "    \n",
    "    # Commodity Channel Index: Identifies cyclical trends\n",
    "    df['CCI'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: CCI values above 100 indicate overbought conditions. CCI values below -100 indicate oversold conditions.\n",
    "    \n",
    "    # Chande Momentum Oscillator: Measures momentum\n",
    "    df['CMO'] = talib.CMO(df['Close'], timeperiod=14)\n",
    "    # Value range: [-100, 100]\n",
    "    # Example: Positive CMO values indicate upward momentum. Negative CMO values indicate downward momentum.\n",
    "    \n",
    "    # Directional Movement Index: Measures trend strength\n",
    "    df['DX'] = talib.DX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Higher DX values indicate a stronger trend. Values above 25 suggest a strong trend.\n",
    "\n",
    "    # Moving Average Convergence/Divergence: Measures momentum\n",
    "    df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive MACD values indicate upward momentum. Negative MACD values indicate downward momentum.\n",
    "    \n",
    "    # MACD with controllable MA type: Measures momentum\n",
    "    df['MACDEXT'], df['MACDEXT_signal'], df['MACDEXT_hist'] = talib.MACDEXT(df['Close'], fastperiod=12, fastmatype=0, slowperiod=26, slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive MACDEXT values indicate upward momentum. Negative MACDEXT values indicate downward momentum.\n",
    "    \n",
    "    # MACD Fix 12/26: Measures momentum\n",
    "    df['MACDFIX'], df['MACDFIX_signal'], df['MACDFIX_hist'] = talib.MACDFIX(df['Close'], signalperiod=9)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive MACDFIX values indicate upward momentum. Negative MACDFIX values indicate downward momentum.\n",
    "\n",
    "    # Money Flow Index: Measures buying and selling pressure\n",
    "    df['MFI'] = talib.MFI(df['High'], df['Low'], df['Close'], df['Volume'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: MFI values above 80 indicate overbought conditions. MFI values below 20 indicate oversold conditions.\n",
    "    \n",
    "    # Minus Directional Indicator: Measures trend strength\n",
    "    df['MINUS_DI'] = talib.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Higher MINUS_DI values indicate a stronger downtrend.\n",
    "    \n",
    "    # Minus Directional Movement: Measures trend strength\n",
    "    df['MINUS_DM'] = talib.MINUS_DM(df['High'], df['Low'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive MINUS_DM values indicate downward movement.\n",
    "    \n",
    "    # Momentum: Measures momentum\n",
    "    df['MOM'] = talib.MOM(df['Close'], timeperiod=10)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive MOM values indicate upward momentum. Negative MOM values indicate downward momentum.\n",
    "    \n",
    "    # Plus Directional Indicator: Measures trend strength\n",
    "    df['PLUS_DI'] = talib.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Higher PLUS_DI values indicate a stronger uptrend.\n",
    "    \n",
    "    # Plus Directional Movement: Measures trend strength\n",
    "    df['PLUS_DM'] = talib.PLUS_DM(df['High'], df['Low'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive PLUS_DM values indicate upward movement.\n",
    "    \n",
    "    # Percentage Price Oscillator: Measures momentum\n",
    "    df['PPO'] = talib.PPO(df['Close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive PPO values indicate upward momentum. Negative PPO values indicate downward momentum.\n",
    "    \n",
    "    # Rate of Change: Measures rate of change\n",
    "    df['ROC'] = talib.ROC(df['Close'], timeperiod=10)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive ROC values indicate upward momentum. Negative ROC values indicate downward momentum.\n",
    "    \n",
    "    # Rate of Change Percentage: Measures rate of change percentage\n",
    "    df['ROCP'] = talib.ROCP(df['Close'], timeperiod=10)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive ROCP values indicate upward momentum. Negative ROCP values indicate downward momentum.\n",
    "\n",
    "    # Rate of Change Ratio: Measures rate of change ratio\n",
    "    df['ROCR'] = talib.ROCR(df['Close'], timeperiod=10)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive ROCR values indicate upward momentum. Negative ROCR values indicate downward momentum.\n",
    "    \n",
    "    # Rate of Change Ratio 100 Scale: Measures rate of change ratio scaled by 100\n",
    "    df['ROCR100'] = talib.ROCR100(df['Close'], timeperiod=10)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive ROCR100 values indicate upward momentum. Negative ROCR100 values indicate downward momentum.\n",
    "    \n",
    "    # Relative Strength Index: Measures momentum\n",
    "    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: RSI values above 70 indicate overbought conditions (potential fall). RSI values below 30 indicate oversold conditions (potential rise).\n",
    "    \n",
    "    # Stochastic: Measures momentum\n",
    "    df['STOCH_slowk'], df['STOCH_slowd'] = talib.STOCH(df['High'], df['Low'], df['Close'], fastk_period=14, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Stochastic values above 80 indicate overbought conditions (potential fall). Stochastic values below 20 indicate oversold conditions (potential rise).\n",
    "    \n",
    "    # Stochastic Fast: Measures momentum\n",
    "    df['STOCHF_fastk'], df['STOCHF_fastd'] = talib.STOCHF(df['High'], df['Low'], df['Close'], fastk_period=14, fastd_period=3, fastd_matype=0)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Fast Stochastic values above 80 indicate overbought conditions (potential fall). Fast Stochastic values below 20 indicate oversold conditions (potential rise).\n",
    "    \n",
    "    # Stochastic Relative Strength Index: Measures momentum\n",
    "    df['STOCHRSI_fastk'], df['STOCHRSI_fastd'] = talib.STOCHRSI(df['Close'], timeperiod=14, fastk_period=14, fastd_period=3, fastd_matype=0)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: Stochastic RSI values above 80 indicate overbought conditions (potential fall). Stochastic RSI values below 20 indicate oversold conditions (potential rise).\n",
    "    \n",
    "    # TRIX: Measures rate of change of a triple smoothed EMA\n",
    "    df['TRIX'] = talib.TRIX(df['Close'], timeperiod=30)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive TRIX values indicate upward momentum. Negative TRIX values indicate downward momentum.\n",
    "    \n",
    "    # Ultimate Oscillator: Measures momentum\n",
    "    df['ULTOSC'] = talib.ULTOSC(df['High'], df['Low'], df['Close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "    # Value range: [0, 100]\n",
    "    # Example: ULTOSC values above 70 indicate overbought conditions (potential fall). ULTOSC values below 30 indicate oversold conditions (potential rise).\n",
    "    \n",
    "    # Williams' %R: Measures overbought/oversold conditions\n",
    "    df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [-100, 0]\n",
    "    # Example: WILLR values above -20 indicate overbought conditions (potential fall). WILLR values below -80 indicate oversold conditions (potential rise).\n",
    "\n",
    "    # Volume Indicators\n",
    "    \n",
    "    # Chaikin A/D Line: Measures accumulation/distribution\n",
    "    df['AD'] = talib.AD(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive AD values indicate accumulation (buying pressure). Negative AD values indicate distribution (selling pressure).\n",
    "    \n",
    "    # Chaikin A/D Oscillator: Measures momentum of the A/D line\n",
    "    df['ADOSC'] = talib.ADOSC(df['High'], df['Low'], df['Close'], df['Volume'], fastperiod=3, slowperiod=10)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive ADOSC values indicate upward momentum. Negative ADOSC values indicate downward momentum.\n",
    "    \n",
    "    # On Balance Volume: Measures buying and selling pressure\n",
    "    df['OBV'] = talib.OBV(df['Close'], df['Volume'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Positive OBV values indicate buying pressure. Negative OBV values indicate selling pressure.\n",
    "\n",
    "    # Volatility Indicators\n",
    "    \n",
    "    # Average True Range: Measures volatility\n",
    "    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Higher ATR values indicate higher volatility.\n",
    "    \n",
    "    # Normalized Average True Range: Measures normalized volatility\n",
    "    df['NATR'] = talib.NATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Higher NATR values indicate higher normalized volatility.\n",
    "    \n",
    "    # True Range: Measures true range\n",
    "    df['TRANGE'] = talib.TRANGE(df['High'], df['Low'], df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Higher TRANGE values indicate a larger range between high, low, and close prices.\n",
    "    \n",
    "    #Cycle Indicators\n",
    "\n",
    "    # Hilbert Transform - Dominant Cycle Period: Identifies dominant cycle period\n",
    "    df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Higher HT_DCPERIOD values indicate a longer dominant cycle period.\n",
    "    \n",
    "    # Hilbert Transform - Dominant Cycle Phase: Identifies dominant cycle phase\n",
    "    df['HT_DCPHASE'] = talib.HT_DCPHASE(df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: HT_DCPHASE values oscillate between 0 and 360 degrees, indicating the phase of the dominant cycle.\n",
    "    \n",
    "    # Hilbert Transform - Phasor Components: Identifies phasor components\n",
    "    df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Inphase and quadrature components help identify the position within the cycle.\n",
    "    \n",
    "    # Hilbert Transform - SineWave: Identifies sinewave components\n",
    "    df['HT_SINE_sine'], df['HT_SINE_leadsine'] = talib.HT_SINE(df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: Sine and leadsine values help identify turning points in the cycle.\n",
    "    \n",
    "    # Hilbert Transform - Trend vs Cycle Mode: Identifies trend vs cycle mode\n",
    "    df['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['Close'])\n",
    "    # Value range: [0, 1]\n",
    "    # Example: A value of 1 indicates a trending market. A value of 0 indicates a cyclical market.\n",
    "    \n",
    "    # Price Transform\n",
    "    \n",
    "    # Average Price: Calculates average price\n",
    "    df['AVGPRICE'] = talib.AVGPRICE(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The average price is calculated as (Open + High + Low + Close) / 4.\n",
    "    \n",
    "    # Median Price: Calculates median price\n",
    "    df['MEDPRICE'] = talib.MEDPRICE(df['High'], df['Low'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The median price is calculated as (High + Low) / 2.\n",
    "    \n",
    "    # Typical Price: Calculates typical price\n",
    "    df['TYPPRICE'] = talib.TYPPRICE(df['High'], df['Low'], df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The typical price is calculated as (High + Low + Close) / 3.\n",
    "    \n",
    "    # Weighted Close Price: Calculates weighted close price\n",
    "    df['WCLPRICE'] = talib.WCLPRICE(df['High'], df['Low'], df['Close'])\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The weighted close price is calculated as (High + Low + 2 * Close) / 4.\n",
    "    \n",
    "    #Statistic Functions\n",
    "\n",
    "    # Beta: Measures volatility relative to the market\n",
    "    df['BETA'] = talib.BETA(df['High'], df['Low'], timeperiod=5)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: A BETA value greater than 1 indicates higher volatility relative to the market. A BETA value less than 1 indicates lower volatility.\n",
    "    \n",
    "    # Pearson's Correlation Coefficient (r): Measures correlation\n",
    "    df['CORREL'] = talib.CORREL(df['High'], df['Low'], timeperiod=30)\n",
    "    # Value range: [-1, 1]\n",
    "    # Example: A CORREL value close to 1 indicates a strong positive correlation. A CORREL value close to -1 indicates a strong negative correlation.\n",
    "    \n",
    "    # Linear Regression: Calculates linear regression\n",
    "    df['LINEARREG'] = talib.LINEARREG(df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The LINEARREG value represents the predicted close price based on the linear regression model.\n",
    "    \n",
    "    # Linear Regression Angle: Calculates linear regression angle\n",
    "    df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: A positive LINEARREG_ANGLE indicates an upward trend. A negative LINEARREG_ANGLE indicates a downward trend.\n",
    "    \n",
    "    # Linear Regression Intercept: Calculates linear regression intercept\n",
    "    df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The LINEARREG_INTERCEPT value represents the intercept of the linear regression line with the y-axis.\n",
    "    \n",
    "    # Linear Regression Slope: Calculates linear regression slope\n",
    "    df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: A positive LINEARREG_SLOPE indicates an upward trend. A negative LINEARREG_SLOPE indicates a downward trend.\n",
    "    \n",
    "    # Standard Deviation: Measures volatility\n",
    "    df['STDDEV'] = talib.STDDEV(df['Close'], timeperiod=5, nbdev=1)\n",
    "    # Value range: [0, positive infinity]\n",
    "    # Example: Higher STDDEV values indicate higher volatility.\n",
    "    \n",
    "    # Time Series Forecast: Forecasts future values\n",
    "    df['TSF'] = talib.TSF(df['Close'], timeperiod=14)\n",
    "    # Value range: [negative infinity, positive infinity]\n",
    "    # Example: The TSF value represents the forecasted close price based on the time series model.\n",
    "    \n",
    "    # Variance: Measures volatility\n",
    "    df['VAR'] = talib.VAR(df['Close'], timeperiod=5, nbdev=1)\n",
    "    # Value range: [0, positive infinity]\n",
    "    # Example: Higher VAR values indicate higher volatility.\n",
    "\n",
    "    # Create new columns in a separate DataFrame\n",
    "    new_columns = pd.DataFrame(index=df.index)\n",
    "\n",
    "    #Trend, 1 indicate rise, -1 indicate fall and 0 indicate neutral\n",
    "    new_columns['DEMA_Trend'] = np.where(df['Close'] > df['DEMA'], 1, np.where(df['Close'] < df['DEMA'], -1, 0))\n",
    "    new_columns['EMA_Trend'] = np.where(df['Close'] > df['EMA'], 1, np.where(df['Close'] < df['EMA'], -1, 0))\n",
    "    new_columns['HT_TRENDLINE_Trend'] = np.where(df['Close'] > df['HT_TRENDLINE'], 1, np.where(df['Close'] < df['HT_TRENDLINE'], -1, 0))\n",
    "    new_columns['KAMA_Trend'] = np.where(df['Close'] > df['KAMA'], 1, np.where(df['Close'] < df['KAMA'], -1, 0))\n",
    "    new_columns['MA_Trend'] = np.where(df['Close'] > df['MA'], 1, np.where(df['Close'] < df['MA'], -1, 0))\n",
    "    new_columns['MAMA_Trend'] = np.where(df['MAMA'] > df['FAMA'], 1, np.where(df['MAMA'] < df['FAMA'], -1, 0))\n",
    "    new_columns['MAVP_Trend'] = np.where(df['Close'] > df['MAVP'], 1, np.where(df['Close'] < df['MAVP'], -1, 0))\n",
    "    new_columns['MIDPOINT_Trend'] = np.where(df['Close'] > df['MIDPOINT'], 1, np.where(df['Close'] < df['MIDPOINT'], -1, 0))\n",
    "    new_columns['MIDPRICE_Trend'] = np.where(df['Close'] > df['MIDPRICE'], 1, np.where(df['Close'] < df['MIDPRICE'], -1, 0))\n",
    "    new_columns['SAR_Trend'] = np.where(df['Close'] > df['SAR'], 1, np.where(df['Close'] < df['SAR'], -1, 0))\n",
    "    new_columns['SAREXT_Trend'] = np.where(df['Close'] > df['SAREXT'], 1, np.where(df['Close'] < df['SAREXT'], -1, 0))\n",
    "    new_columns['SMA_Trend'] = np.where(df['Close'] > df['SMA'], 1, np.where(df['Close'] < df['SMA'], -1, 0))\n",
    "    new_columns['T3_Trend'] = np.where(df['Close'] > df['T3'], 1, np.where(df['Close'] < df['T3'], -1, 0))\n",
    "    new_columns['TEMA_Trend'] = np.where(df['Close'] > df['TEMA'], 1, np.where(df['Close'] < df['TEMA'], -1, 0))\n",
    "    new_columns['TRIMA_Trend'] = np.where(df['Close'] > df['TRIMA'], 1, np.where(df['Close'] < df['TRIMA'], -1, 0))\n",
    "    new_columns['WMA_Trend'] = np.where(df['Close'] > df['WMA'], 1, np.where(df['Close'] < df['WMA'], -1, 0))\n",
    "    new_columns['ADX_Trend'] = np.where(df['ADX'] > 25, 1, np.where(df['ADX'] <= 25, -1, 0))\n",
    "    new_columns['ADXR_Trend'] = np.where(df['ADXR'] > 25, 1, np.where(df['ADXR'] <= 25, -1, 0))\n",
    "    new_columns['AROONOSC_Trend'] = np.where(df['AROONOSC'] > 0, 1, np.where(df['AROONOSC'] <= 0, -1, 0))\n",
    "    new_columns['DX_Trend'] = np.where(df['DX'] > 25, 1, np.where(df['DX'] <= 25, -1, 0))\n",
    "    new_columns['TRIX_Trend'] = np.where(df['TRIX'] > 0, 1, np.where(df['TRIX'] <= 0, -1, 0))\n",
    "    new_columns['DMI_Trend'] = np.where(df['PLUS_DI'] > df['MINUS_DI'], 1, np.where(df['PLUS_DI'] <= df['MINUS_DI'], -1, 0))\n",
    "\n",
    "    new_columns['AROON_Up_Trend'] = np.where(df['AROON_up'] > 50, 1, np.where(df['AROON_up'] <= 50, -1, 0))\n",
    "    new_columns['AROON_Down_Trend'] = np.where(df['AROON_down'] > 50, 1, np.where(df['AROON_down'] <= 50, -1, 0))\n",
    "    new_columns['PM_Uptrend'] = np.where(df['PLUS_DI'] > df['MINUS_DI'], 1, np.where(df['PLUS_DI'] <= df['MINUS_DI'], -1, 0))\n",
    "    new_columns['PM_Downtrend'] = np.where(df['MINUS_DI'] > df['PLUS_DI'], 1, np.where(df['MINUS_DI'] <= df['PLUS_DI'], -1, 0))\n",
    "\n",
    "    new_columns['ROC_Trend'] = np.where(df['ROC'] > 0, 1, np.where(df['ROC'] <= 0, -1, 0))\n",
    "    new_columns['ROCP_Trend'] = np.where(df['ROCP'] > 0, 1, np.where(df['ROCP'] <= 0, -1, 0))\n",
    "    new_columns['ROCR_Trend'] = np.where(df['ROCR'] > 0, 1, np.where(df['ROCR'] <= 0, -1, 0))\n",
    "    new_columns['ROCR100_Trend'] = np.where(df['ROCR100'] > 0, 1, np.where(df['ROCR100'] <= 0, -1, 0))\n",
    "            \n",
    "    #Buy/Sell Signal, 1 indicate buy which will rise, -1 indicate sell which will fall and 0 indicate neutral\n",
    "\n",
    "    new_columns['ROC_Buy_Sell_Signal'] = np.where(df['ROC'] > 0, 1, np.where(df['ROC'] < 0, -1, 0))\n",
    "    new_columns['ROCP_Buy_Sell_Signal'] = np.where(df['ROCP'] > 0, 1, np.where(df['ROCP'] < 0, -1, 0))\n",
    "    new_columns['ROCR_Buy_Sell_Signal'] = np.where(df['ROCR'] > 0, 1, np.where(df['ROCR'] < 0, -1, 0))\n",
    "    new_columns['ROCR100_Buy_Sell_Signal'] = np.where(df['ROCR100'] > 0, 1, np.where(df['ROCR100'] < 0, -1, 0))\n",
    "\n",
    "    new_columns['APO_Buy_Sell_Signal'] = np.where(df['APO'] > 0, 1, -1)\n",
    "    new_columns['MACD_Buy_Sell_Signal'] = np.where(df['MACD'] > df['MACD_signal'], 1, -1)\n",
    "    new_columns['MACDEXT_Buy_Sell_Signal'] = np.where(df['MACDEXT'] > df['MACDEXT_signal'], 1, -1)\n",
    "    new_columns['MACDFIX_Buy_Sell_Signal'] = np.where(df['MACDFIX'] > df['MACDFIX_signal'], 1, -1)\n",
    "    new_columns['PPO_Buy_Sell_Signal'] = np.where(df['PPO'] > 0, 1, -1)\n",
    "    new_columns['MOM_Buy_Sell_Signal'] = np.where(df['MOM'] > 0, 1, -1)\n",
    "    new_columns['STOCH_Buy_Sell_Signal'] = np.where(df['STOCH_slowk'] > df['STOCH_slowd'], 1, -1)\n",
    "    new_columns['STOCHF_Buy_Sell_Signal'] = np.where(df['STOCHF_fastk'] > df['STOCHF_fastd'], 1, -1)\n",
    "    new_columns['STOCHRSI_Buy_Sell_Signal'] = np.where(df['STOCHRSI_fastk'] > df['STOCHRSI_fastd'], 1, -1)\n",
    "    new_columns['ULTOSC_Buy_Sell_Signal'] = np.where(df['ULTOSC'] > 50, 1, -1)\n",
    "    new_columns['WILLR_Buy_Sell_Signal'] = np.where(df['WILLR'] > -80, 1, np.where(df['WILLR'] < -20, -1, 0))\n",
    "\n",
    "    #Buy/Sell Pressure, 1 indicate buy pressure which will rise, -1 indicate sell pressure which will fall and 0 indicate neutral\n",
    "    new_columns['BOP_Buy_Sell_Pressure'] = np.where(df['BOP'] <= 0, -1, 1)\n",
    "    new_columns['MFI_Buy_Sell_Pressure'] = np.where(df['MFI'] <= 50, -1, 1)\n",
    "    new_columns['AD_Buy_Sell_Pressure'] = np.where(df['AD'] > 0, 1, -1)\n",
    "    new_columns['ADOSC_Buy_Sell_Pressure'] = np.where(df['ADOSC'] > 0, 1, -1)\n",
    "    new_columns['OBV_Buy_Sell_Pressure'] = np.where(df['OBV'] > 0, 1, -1)\n",
    "    \n",
    "    # Overbought/Oversold Indicators,1 indicate overbought which will rise, -1 indicate oversold which will fall and 0 indicate neutral\n",
    "    new_columns['BB_Overbought_Oversold_Signal'] = np.where(df['Close'] <= df['BB_LOWER'], -1, np.where(df['Close'] >= df['BB_UPPER'], 1, 0))\n",
    "    new_columns['CCI_Overbought_Oversold_Signal'] = np.where(df['CCI'] < -100, -1, np.where(df['CCI'] > 100, 1, 0))\n",
    "    new_columns['RSI_Overbought_Oversold_Signal'] = np.where(df['RSI'] < 30, -1, np.where(df['RSI'] > 70, 1, 0))\n",
    "    new_columns['STOCH_Overbought_Oversold_Signal'] = np.where(df['STOCH_slowk'] > 80, 1, np.where(df['STOCH_slowk'] < 20, -1, 0))\n",
    "    new_columns['STOCHF_Overbought_Oversold_Signal'] = np.where(df['STOCHF_fastk'] > 80, 1, np.where(df['STOCHF_fastk'] < 20, -1, 0))\n",
    "    new_columns['STOCHRSI_Overbought_Oversold_Signal'] = np.where(df['STOCHRSI_fastk'] > 80, 1, np.where(df['STOCHRSI_fastk'] < 20, -1, 0))\n",
    "    new_columns['ULTOSC_Overbought_Oversold_Signal'] = np.where(df['ULTOSC'] > 70, 1, np.where(df['ULTOSC'] < 30, -1, 0))\n",
    "    new_columns['WILLR_Overbought_Oversold_Signal'] = np.where(df['WILLR'] > -20, 1, np.where(df['WILLR'] < -80, -1, 0))\n",
    "\n",
    "    ## Reserve Indicators, 1 indicate going bullish which will rise, -1 indicate going bearish which will fall and 0 indicate neutral\n",
    "    new_columns['BB_RSI_Reversal'] = np.where((df['Close'] < df['BB_LOWER']) & (df['RSI'] < 30) & (df['RSI'].shift(1) < df['RSI']), 1, np.where((df['Close'] > df['BB_UPPER']) & (df['RSI'] > 70) & (df['RSI'].shift(1) > df['RSI']), -1, 0))\n",
    "\n",
    "    ## Volatility Indicators, 1 indicate low volatility, -1 indicate high volatitlity and 0 indicate neutral\n",
    "    new_columns['BB_Volatility'] = np.where((df['Close'] > df['BB_UPPER']) | (df['Close'] < df['BB_LOWER']), -1, np.where((df['Close'] <= df['BB_UPPER']) & (df['Close'] >= df['BB_LOWER']), 1, 0))\n",
    "    new_columns['ATR_Volatility'] = np.where(df['ATR'] > df['ATR'].rolling(window=14).mean(), -1, np.where(df['ATR'] <= df['ATR'].rolling(window=14).mean(), 1, 0))\n",
    "    new_columns['NATR_Volatility'] = np.where(df['NATR'] > df['NATR'].rolling(window=14).mean(), -1, np.where(df['NATR'] <= df['NATR'].rolling(window=14).mean(), 1, 0))\n",
    "    new_columns['TRANGE_Volatility'] = np.where(df['TRANGE'] > df['TRANGE'].rolling(window=14).mean(), -1, np.where(df['TRANGE'] <= df['TRANGE'].rolling(window=14).mean(), 1, 0))\n",
    "\n",
    "\n",
    "     # Pattern Recognition\n",
    "\n",
    "    # Get all candlestick pattern functions\n",
    "    all_functions = talib.get_function_groups()\n",
    "    candlestick_patterns = all_functions['Pattern Recognition']\n",
    "    patterns = {pattern: getattr(talib, pattern) for pattern in candlestick_patterns}\n",
    "\n",
    "    # Initialize Pattern_Sum column\n",
    "    new_columns['PATTERN_SUM'] = 0\n",
    "\n",
    "    # Apply each pattern function to the DataFrame and sum the results\n",
    "    for pattern_name, pattern_func in patterns.items():\n",
    "        pattern_result = pattern_func(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "        new_columns['PATTERN_SUM'] += pattern_result\n",
    "\n",
    "    # Normalize the summed pattern values to be within the range of -1 to 1\n",
    "    new_columns['PATTERN_SUM'] = new_columns['PATTERN_SUM'].apply(lambda x: np.clip(x, -100, 100) / 100)\n",
    "    # Value range: [-1, 1]\n",
    "    # Example: -1 bearish , 0 no detection, 1 bullish\n",
    "\n",
    "    # Concatenate the new columns with the original DataFrame\n",
    "    df = pd.concat([df, new_columns], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def set_target(df):\n",
    "    # Create new columns in a separate DataFrame\n",
    "    new_columns = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Shift the 'Close' column by one to get the next day's close price\n",
    "    new_columns['NEXT_DAY_CLOSEPRICE'] = df['Close'].shift(-1)\n",
    "    \n",
    "    # Calculate the change in close price from one day to the next\n",
    "    new_columns['DAILY_CLOSEPRICE_CHANGE'] = new_columns['NEXT_DAY_CLOSEPRICE'] - df['Close']\n",
    "\n",
    "    # Calculate the percentage change in close price\n",
    "    new_columns['DAILY_CLOSEPRICE_CHANGE_PERCENT'] = (new_columns['DAILY_CLOSEPRICE_CHANGE'] / df['Close'])\n",
    "\n",
    "    # Determine the direction of the close price change\n",
    "    new_columns['DAILY_CLOSEPRICE_DIRECTION'] = np.sign(new_columns['DAILY_CLOSEPRICE_CHANGE'])\n",
    "    \n",
    "    # Calculate the daily mid price as the average of the high and low prices\n",
    "    new_columns['DAILY_MIDPRICE'] = (df['High'] + df['Low']) / 2\n",
    "    \n",
    "    # Shift the 'DAILY_MIDPRICE' column by one to get the next day's mid price\n",
    "    new_columns['NEXT_DAY_MIDPRICE'] = new_columns['DAILY_MIDPRICE'].shift(-1)\n",
    "    \n",
    "    # Calculate the change in mid price from one day to the next\n",
    "    new_columns['DAILY_MIDPRICE_CHANGE'] = new_columns['NEXT_DAY_MIDPRICE'] - new_columns['DAILY_MIDPRICE']\n",
    "\n",
    "    # Calculate the percentage change in mid price\n",
    "    new_columns['DAILY_MIDPRICE_CHANGE_PERCENT'] = (new_columns['DAILY_MIDPRICE_CHANGE'] / new_columns['DAILY_MIDPRICE'])\n",
    "\n",
    "    # Determine the direction of the mid price change\n",
    "    new_columns['DAILY_MIDPRICE_DIRECTION'] = np.sign(new_columns['DAILY_MIDPRICE_CHANGE'])\n",
    "    \n",
    "    # Handle the last row where changes are NaN\n",
    "    new_columns.at[df.index[-1], 'DAILY_CLOSEPRICE_CHANGE'] = np.nan\n",
    "    new_columns.at[df.index[-1], 'DAILY_CLOSEPRICE_CHANGE_PERCENT'] = np.nan\n",
    "    new_columns.at[df.index[-1], 'DAILY_CLOSEPRICE_DIRECTION'] = np.nan\n",
    "    new_columns.at[df.index[-1], 'DAILY_MIDPRICE_CHANGE'] = np.nan\n",
    "    new_columns.at[df.index[-1], 'DAILY_MIDPRICE_CHANGE_PERCENT'] = np.nan\n",
    "    new_columns.at[df.index[-1], 'DAILY_MIDPRICE_DIRECTION'] = np.nan\n",
    "    \n",
    "    # Concatenate the new columns with the original DataFrame\n",
    "    df = pd.concat([df, new_columns], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Explanation:\n",
    "# - Close Price: Used for end-of-day analysis and long-term trend predictions. It is stable and widely used in technical indicators.\n",
    "# - Mid Price: Useful for intraday analysis and understanding market liquidity. It provides a more granular view of price movements within the trading day.\n",
    "# - Price Differences: Using differences (e.g., DAILY_CLOSEPRICE_CHANGE) instead of actual prices (e.g., NEXT_DAY_CLOSEPRICE) helps in normalizing the data, making it more comparable across different stocks and time periods. \n",
    "#   It also simplifies trend analysis and can improve model performance by focusing on the direction and magnitude of price changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad947883-9fc8-4584-9e0c-27f9eee135f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_two_words(text):\n",
    "    words = text.split()\n",
    "    return ' '.join(words[:-2])\n",
    "    \n",
    "def get_data_from_yahoo_finance(ticker_symbol, start_date, end_date):\n",
    "    df = None\n",
    "    query_search = []\n",
    "    try:\n",
    "        df = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "            \n",
    "        stock = yf.Ticker(ticker_symbol)\n",
    "        info = stock.info\n",
    "        query_search.append(ticker_symbol)\n",
    "            \n",
    "        ticker_type = info.get('quoteType', 'Unknown')\n",
    "        if ticker_type == 'EQUITY':\n",
    "            company_name = info.get('shortName', '')\n",
    "            #industry = info.get('industry', '')\n",
    "            #sector = info.get('sector', '')\n",
    "            query_search.append(company_name)\n",
    "            #query_search.append(industry)\n",
    "            #query_search.append(sector)\n",
    "        elif ticker_type == 'CURRENCY':\n",
    "            currency_name = info.get('currency', '')\n",
    "            query_search.append(currency_name)\n",
    "        elif ticker_type == 'FUTURE':\n",
    "            commodity_name = info.get('shortName', '')\n",
    "            commodity_name = remove_last_two_words(commodity_name)\n",
    "            query_search.append(commodity_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker_symbol}: {e}\")\n",
    "\n",
    "    return df,query_search\n",
    "\n",
    "def get_commod_data_from_csv(file_path):\n",
    "  df = pd.read_csv(file_path)\n",
    "  df.rename(columns={'Settle': 'Close'}, inplace=True)\n",
    "  return df\n",
    "\n",
    "def split_train_and_test_data_and_save(df, days, ticker_symbol):\n",
    "    cutoff_date = df.index.max() - timedelta(days=days)\n",
    "    train_df = df[df.index < cutoff_date]\n",
    "    test_df1 = train_df.tail(30).copy(deep=True)\n",
    "    test_df2 = df[df.index >= cutoff_date]\n",
    "\n",
    "    test_df = pd.concat([test_df1, test_df2])\n",
    "        \n",
    "    train_df.to_csv(f'../data/train/{ticker_symbol}.csv')\n",
    "    test_df.to_csv(f'../data/test/{ticker_symbol}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a86c1c8-0626-45a2-9206-bdc0017e67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "def create_col_names(no_of_components):\n",
    "    x = 1\n",
    "    columns = []\n",
    "    while x <= no_of_components:\n",
    "        columns.append(f'PC{x}')\n",
    "        x += 1\n",
    "    return columns\n",
    "\n",
    "def filter_PCAs_via_eigen(principal_components):\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    # Filter PCs with eigenvalues greater than 1\n",
    "    pcs_greater_than_1_indices = [i for i, eigenvalue in enumerate(eigenvalues) if eigenvalue > 1]\n",
    "    print(\"Principal Components with Eigenvalues > 1:\", pcs_greater_than_1_indices)\n",
    "    filtered_principal_components = principal_components[:, pcs_greater_than_1_indices]\n",
    "    return pcs_greater_than_1_indices, filtered_principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747ac9f0-f185-4272-998a-ed61f139fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components with Eigenvalues > 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components with Eigenvalues > 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components with Eigenvalues > 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components with Eigenvalues > 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "news_sentiment = NewsSentiment()\n",
    "\n",
    "# Check if the ticker symbol file exists\n",
    "if not os.path.isfile(ticker_symbol_file):\n",
    "    print(f\"Ticker symbol file '{ticker_symbol_file}' does not exist.\")\n",
    "else:\n",
    "    # Ensure the data directory exists\n",
    "    os.makedirs('../data/train', exist_ok=True)\n",
    "    os.makedirs('../data/test', exist_ok=True)\n",
    "\n",
    "    # Read ticker symbols from file\n",
    "    with open(ticker_symbol_file, 'r') as file:\n",
    "        ticker_symbols = file.readlines()\n",
    "\n",
    "    ticker_symbol_list = [ticker_symbol.strip() for ticker_symbol in ticker_symbols]\n",
    "    end_date = datetime.today()\n",
    "    start_date = end_date - timedelta(days=3*365)\n",
    "\n",
    "    for ticker_symbol in ticker_symbol_list:\n",
    "        df , query_search = get_data_from_yahoo_finance(ticker_symbol, start_date, end_date)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        df = get_technical_indicator(df)\n",
    "        df = get_news_sentiment_score(df, query_search)\n",
    "        df = set_target(df)\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        columns_to_drop_temp = ['NEXT_DAY_CLOSEPRICE', 'DAILY_CLOSEPRICE_CHANGE', 'DAILY_CLOSEPRICE_CHANGE_PERCENT', 'DAILY_CLOSEPRICE_DIRECTION',\n",
    "        'DAILY_MIDPRICE', 'NEXT_DAY_MIDPRICE', 'DAILY_MIDPRICE_CHANGE', 'DAILY_MIDPRICE_CHANGE_PERCENT', 'DAILY_MIDPRICE_DIRECTION', 'Date', \n",
    "        'SENTIMENT_NEGATIVE', 'SENTIMENT_POSITIVE', 'SENTIMENT_UNCERTAINTY', 'SENTIMENT_LITIGIOUS',\t'SENTIMENT_STRONG_MODAL', 'SENTIMENT_WEAK_MODAL', 'SENTIMENT_CONSTRAINING',\n",
    "        'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        \n",
    "        for col in columns_to_drop_temp:\n",
    "            if col not in df.columns:\n",
    "                columns_to_drop_temp.remove(col)\n",
    "\n",
    "        df = df.drop(columns=columns_to_drop_temp)\n",
    "        \n",
    "        # Replace missing values with the median for each column\n",
    "        df.fillna(df.median(), inplace=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "        pca = PCA()  # Choose the number of components\n",
    "        principal_components = pca.fit_transform(scaled_data)\n",
    "        # keep only PCs with eigen value more than 1\n",
    "        pcs_greater_than_1_indices, filtered_principal_components = filter_PCAs_via_eigen(principal_components)\n",
    "        columns = create_col_names(len(pcs_greater_than_1_indices))\n",
    "        pca_df = pd.DataFrame(data=filtered_principal_components, columns=columns)\n",
    "\n",
    "        pca_df.index = df_copy.index\n",
    "\n",
    "        # Insert back columns\n",
    "        df_selected = df_copy[columns_to_drop_temp]\n",
    "        \n",
    "        pca_df = pd.concat([pca_df, df_selected], axis=1)\n",
    "\n",
    "        split_train_and_test_data_and_save(pca_df, 90, ticker_symbol)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d91a02-6661-4e23-a67c-86294a07e4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components with Eigenvalues > 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "commodities_folder_path = '../data/commodities_historical_data'\n",
    "os.makedirs(f'{commodities_folder_path}/original', exist_ok=True)\n",
    "os.makedirs(f'{commodities_folder_path}/processed', exist_ok=True)\n",
    "for filename in os.listdir(f'{commodities_folder_path}/original'):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "        file_path = os.path.join(f'{commodities_folder_path}/original', filename)\n",
    "        commodity_name = filename.split('.')[0]\n",
    "        # Load CSV into a pandas DataFrame\n",
    "        df = get_commod_data_from_csv(file_path)\n",
    "        df = get_technical_indicator(df)\n",
    "        query_search = []\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['Date'] = df['Date'].dt.tz_convert(None)\n",
    "        df.index = df['Date']\n",
    "        query_search.append(commodity_name)\n",
    "        df = get_news_sentiment_score(df, query_search)\n",
    "        df = set_target(df)\n",
    "        # drop non-index Date column\n",
    "        df = df.drop(columns='Date')\n",
    "        df.to_csv(f'{commodities_folder_path}/processed/{commodity_name}.csv')\n",
    "        \n",
    "        df_copy = df.copy()\n",
    "\n",
    "        columns_to_drop_temp = ['NEXT_DAY_CLOSEPRICE', 'DAILY_CLOSEPRICE_CHANGE', 'DAILY_CLOSEPRICE_CHANGE_PERCENT', 'DAILY_CLOSEPRICE_DIRECTION',\n",
    "        'DAILY_MIDPRICE', 'NEXT_DAY_MIDPRICE', 'DAILY_MIDPRICE_CHANGE', 'DAILY_MIDPRICE_CHANGE_PERCENT', 'DAILY_MIDPRICE_DIRECTION', 'Date', \n",
    "        'SENTIMENT_NEGATIVE', 'SENTIMENT_POSITIVE', 'SENTIMENT_UNCERTAINTY', 'SENTIMENT_LITIGIOUS',\t'SENTIMENT_STRONG_MODAL', 'SENTIMENT_WEAK_MODAL', 'SENTIMENT_CONSTRAINING',\n",
    "        'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        \n",
    "        for col in columns_to_drop_temp:\n",
    "            if col not in df.columns:\n",
    "                columns_to_drop_temp.remove(col)\n",
    "\n",
    "        df = df.drop(columns=columns_to_drop_temp)\n",
    "        \n",
    "        # Replace missing values with the median for each column\n",
    "        df.fillna(df.median(), inplace=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "        pca = PCA()  # Choose the number of components\n",
    "        principal_components = pca.fit_transform(scaled_data)\n",
    "        # keep only PCs with eigen value more than 1\n",
    "        pcs_greater_than_1_indices, filtered_principal_components = filter_PCAs_via_eigen(principal_components)\n",
    "        columns = create_col_names(len(pcs_greater_than_1_indices))\n",
    "        pca_df = pd.DataFrame(data=filtered_principal_components, columns=columns)\n",
    "\n",
    "        pca_df.index = df_copy.index\n",
    "\n",
    "        # Insert back columns\n",
    "        df_selected = df_copy[columns_to_drop_temp]\n",
    "        \n",
    "        pca_df = pd.concat([pca_df, df_selected], axis=1)\n",
    "        \n",
    "        split_train_and_test_data_and_save(pca_df, 90, commodity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f49a23-baef-4d50-b4f2-c46ea210443a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db3f1b-5538-4d46-ab25-600e4e54bfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
